{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a4fc653-fbe6-436d-b002-f6018b18d75e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TEIXML2TEXT\n",
    "\n",
    "This notebook tries to generate exactly two witnesses from a given TEI XML document.\n",
    "\n",
    "The idea is to treat the edit operations in exactly two different ways:\n",
    "\n",
    "1. Witness 1: apply only the instant edit operations to the document. Ignore all other edit operations.\n",
    "2. Witness 2: apply all remaining edit operations to the document.\n",
    "\n",
    "NB: remember to retain the subst edit operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeccbb1-0468-447f-a1c4-ac911a745c9e",
   "metadata": {},
   "source": [
    "#### 1. Add unique identifiers to each edit operations\n",
    "\n",
    "Adds an 'id' attribute to every edit operation. This makes it easier to refer to specific edit operations later on (if we want to remove or apply specific ones)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84f35285-5ecf-4150-b57a-3b144fb63408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from bs4.element import Tag\n",
    "import re\n",
    "import json\n",
    "\n",
    "def add_ids_to_edit_ops(filepath):\n",
    "    with open(filepath, \"r\") as file:\n",
    "        soup = BeautifulSoup(file, features=\"lxml-xml\")\n",
    "    \n",
    "    tag_index = []\n",
    "    add_tag_counter = 1\n",
    "    del_tag_counter = 1\n",
    "    subst_tag_counter = 1\n",
    "    for tag in soup.find_all():\n",
    "        if tag.name == \"add\":\n",
    "            tag['id'] = add_tag_counter\n",
    "            add_tag_counter += 1\n",
    "        if tag.name == \"del\":\n",
    "            tag['id'] = del_tag_counter\n",
    "            del_tag_counter += 1\n",
    "        if tag.name == \"subst\":\n",
    "            tag['id'] = subst_tag_counter\n",
    "            subst_tag_counter += 1\n",
    "    \n",
    "    filepath_parts = filepath.split(\".\")\n",
    "    if len(filepath_parts) <= 1:\n",
    "        raise Exception(\"no valid filepath or file extension specified for the input file\")\n",
    "      \n",
    "    file_extension = filepath_parts[len(filepath_parts)-1]\n",
    "    filepath_parts.pop()\n",
    "    filepath_parts.append('_ids_added.')\n",
    "    filepath_parts.append(file_extension)\n",
    "    output_filepath = ''.join(filepath_parts) \n",
    "    \n",
    "    with open(output_filepath, \"w\", encoding='utf-8') as file:\n",
    "        file.write(str(soup))\n",
    "\n",
    "add_ids_to_edit_ops(\"datasets/clean-data/ms-aladin-simplified.xml\")\n",
    "\n",
    "with open(\"datasets/clean-data/ms-aladin-simplified_ids_added.xml\", \"r\") as file:\n",
    "    soup = BeautifulSoup(file, features=\"lxml-xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60126fb7-aecc-43ba-9244-335f1bcfb946",
   "metadata": {},
   "source": [
    "#### 2. Define functions to remove / apply specific edit operations\n",
    "\n",
    "These functions will be called when we want to remove or apply specific edit operations to transform the TEI/XML document to pure text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "994d369f-dcbf-41b6-a3ca-1f882acd64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_child_of(edit1, edit2):\n",
    "    if (edit1.name in [\"add\", \"del\", \"subst\"]) and (edit2.name in [\"add\", \"del\", \"subst\"]):\n",
    "        children = edit2.findChildren(re.compile('.*') , recursive=False)\n",
    "        if edit1 in children:\n",
    "            return True\n",
    "        else:\n",
    "            return is_child_of_entity_in(edit1, children)\n",
    "    return False\n",
    "        \n",
    "def is_child_of_entity_in(edit, edits):\n",
    "    # if edit in edits:\n",
    "    #     edits.remove(edit)\n",
    "    for e in edits:\n",
    "        if is_child_of(edit, e):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_child_edits(edits):\n",
    "    result = []\n",
    "    for edit in edits:\n",
    "        if not is_child_of_entity_in(edit, edits):\n",
    "            result.append(edit)\n",
    "    return result\n",
    "\n",
    "def get_deepest_nested_tag(list_of_tags):\n",
    "    deepest = {\"tag\" : None, \"depth\" : -1}\n",
    "    for tag in list_of_tags:\n",
    "        tag_depth = {\"tag\" : tag, \"depth\" : get_tag_nesting_depth(tag, depth=1)}\n",
    "        if tag_depth[\"depth\"] > deepest[\"depth\"]:\n",
    "            deepest = tag_depth\n",
    "    return deepest[\"tag\"]\n",
    "\n",
    "def get_tag_nesting_depth(tag, depth=1):\n",
    "    children = tag.findChildren(re.compile('.*') , recursive=False)\n",
    "    if len(children) == 0:\n",
    "        return depth\n",
    "    else:\n",
    "        depth += 1\n",
    "        return get_tag_nesting_depth(get_deepest_nested_tag(children), depth=depth)\n",
    "    \n",
    "def get_deepest_tag(tag, depth=1):\n",
    "    children = tag.findChildren(re.compile('.*') , recursive=False)\n",
    "    if len(children) == 0:\n",
    "        return tag\n",
    "    else:\n",
    "        depth += 1\n",
    "        return get_deepest_nested_tag(children)\n",
    "    \n",
    "def apply_multiple_edit_ops(soup_obj, edit_ids=[], edit_ops=[]):\n",
    "    if ((len(edit_ids) == 0) and (len(edit_ops) == 0)):\n",
    "        raise Exception(\"No edit operations specified.\")\n",
    "    elif (len(edit_ids) == 0):\n",
    "        for edit_op in edit_ops:\n",
    "            if (type(edit_op) is not Tag):\n",
    "                raise Exception(\"Edit ID\",edit_id,\"is not a valid edit operation ID. Must be an integer greater equal to 1.\")            \n",
    "            else:\n",
    "                # print()\n",
    "                # print(\"processing edit...tag name: \", edit_op.name, \", text: \", edit_op.text, \"...\")\n",
    "                # print()\n",
    "                soup_obj = apply_single_edit_op(soup_obj, edit_op=edit_op)          \n",
    "    elif (len(edit_ops) == 0):\n",
    "        for edit_id in edit_ids:\n",
    "            if (int(edit_id) < 1):\n",
    "                raise Exception(\"Edit ID\",edit_id,\"is not a valid edit operation ID. Must be an integer greater equal to 1.\")\n",
    "            else:\n",
    "                soup_obj = apply_single_edit_op(soup_obj, edit_id=edit_id)\n",
    "    else:\n",
    "        for edit_id in edit_ids:\n",
    "            if (int(edit_id) < 1):\n",
    "                raise Exception(\"Edit ID\",edit_id,\"is not a valid edit operation ID. Must be an integer greater equal to 1.\")\n",
    "            else:\n",
    "                soup_obj = apply_single_edit_op(soup_obj, edit_id=edit_id)        \n",
    "    return soup_obj\n",
    "\n",
    "def ignore_multiple_edit_ops(soup_obj, edit_ids=[], edit_ops=[]):\n",
    "    if ((len(edit_ids) == 0) and (len(edit_ops) == 0)):\n",
    "        raise Exception(\"No edit operations specified.\")\n",
    "    elif (len(edit_ids) == 0):\n",
    "        for edit_op in edit_ops:\n",
    "            if (type(edit_op) is not Tag):\n",
    "                raise Exception(\"Edit ID\",edit_id,\"is not a valid edit operation ID. Must be an integer greater equal to 1.\")            \n",
    "            else:\n",
    "                # print()\n",
    "                # print(\"processing edit...tag name: \", edit_op.name, \", text: \", edit_op.text, \"...\")\n",
    "                # print()\n",
    "                soup_obj = ignore_single_edit_op(soup_obj, edit_op=edit_op)          \n",
    "    elif (len(edit_ops) == 0):\n",
    "        for edit_id in edit_ids:\n",
    "            if (int(edit_id) < 1):\n",
    "                raise Exception(\"Edit ID\",edit_id,\"is not a valid edit operation ID. Must be an integer greater equal to 1.\")\n",
    "            else:\n",
    "                soup_obj = ignore_single_edit_op(soup_obj, edit_id=edit_id)\n",
    "    else:\n",
    "        for edit_id in edit_ids:\n",
    "            if (int(edit_id) < 1):\n",
    "                raise Exception(\"Edit ID\",edit_id,\"is not a valid edit operation ID. Must be an integer greater equal to 1.\")\n",
    "            else:\n",
    "                soup_obj = ignore_single_edit_op(soup_obj, edit_id=edit_id)        \n",
    "    return soup_obj\n",
    "\n",
    "def apply_single_edit_op(soup_obj, edit_id=-1, edit_op=None):\n",
    "    if ((edit_id == -1) and (edit_op is None)):\n",
    "        raise Exception(\"A valid edit operation is not specified.\")\n",
    "    elif (edit_id == -1):\n",
    "        if (type(edit_op) is not Tag):\n",
    "            raise Exception(\"Edit operation\",edit_op,\"is not a valid bs4.element.Tag object\")\n",
    "        else:\n",
    "            tag_nesting_depth = get_tag_nesting_depth(edit_op)\n",
    "            # print(edit_op.name, \" nesting depth: \", tag_nesting_depth)\n",
    "            # print()\n",
    "            if (tag_nesting_depth == 1):\n",
    "                # print(\"terminating condition\")\n",
    "                if (edit_op.name == \"add\"):\n",
    "                    # print(\"add: \", edit_op['id'], \" - \", edit_op)\n",
    "                    if soup_obj.find(\"add\", {\"id\": edit_op['id']}) is not None:\n",
    "                        soup_obj.find(\"add\", {\"id\": edit_op['id']}).unwrap()\n",
    "                elif (edit_op.name == \"del\"):\n",
    "                    # print(\"del: \", edit_op['id'], \" - \", edit_op)\n",
    "                    if soup_obj.find(\"del\", {\"id\": edit_op['id']}) is not None:\n",
    "                        soup_obj.find(\"del\", {\"id\": edit_op['id']}).extract()\n",
    "                elif (edit_op.name == \"subst\"):\n",
    "                    if soup_obj.find(\"subst\", {\"id\": edit_op['id']}) is not None:\n",
    "                        soup_obj.find(\"subst\", {\"id\": edit_op['id']}).unwrap()\n",
    "            else:\n",
    "                # print(\"recursing\")\n",
    "                children = edit_op.findChildren(re.compile('.*') , recursive=False)\n",
    "                # print(\"children: \", len(children))\n",
    "                count = 1\n",
    "                for child in children:\n",
    "                    # print(\"child \", count, \":\", child)\n",
    "                    soup_obj = apply_single_edit_op(soup_obj, edit_op=child)\n",
    "                    count += 1\n",
    "                soup_obj = apply_single_edit_op(soup_obj, edit_op=edit_op)\n",
    "    return soup_obj\n",
    "        \n",
    "def ignore_single_edit_op(soup_obj, edit_id=-1, edit_op=None):\n",
    "    if ((edit_id == -1) and (edit_op is None)):\n",
    "        raise Exception(\"A valid edit operation is not specified.\")\n",
    "    elif (edit_id == -1):\n",
    "        if (type(edit_op) is not Tag):\n",
    "            raise Exception(\"Edit operation\",edit_op,\"is not a valid bs4.element.Tag object\")\n",
    "        else:\n",
    "            tag_nesting_depth = get_tag_nesting_depth(edit_op)\n",
    "            if (tag_nesting_depth == 1):\n",
    "                if (edit_op.name == \"add\"):\n",
    "                    if soup_obj.find(\"add\", {\"id\": edit_op['id']}) is not None:\n",
    "                        soup_obj.find(\"add\", {\"id\": edit_op['id']}).extract()\n",
    "                elif (edit_op.name == \"del\"):\n",
    "                    if soup_obj.find(\"del\", {\"id\": edit_op['id']}) is not None:\n",
    "                        soup_obj.find(\"del\", {\"id\": edit_op['id']}).unwrap()\n",
    "                elif (edit_op.name == \"subst\"):\n",
    "                    if soup_obj.find(\"subst\", {\"id\": edit_op['id']}) is not None:\n",
    "                        soup_obj.find(\"subst\", {\"id\": edit_op['id']}).unwrap()\n",
    "            else:\n",
    "                children = edit_op.findChildren(re.compile('.*') , recursive=False)\n",
    "                count = 1\n",
    "                for child in children:\n",
    "                    ignore_single_edit_op(soup_obj, edit_op=child)\n",
    "                    count += 1\n",
    "                ignore_single_edit_op(soup_obj, edit_op=edit_op)\n",
    "    return soup_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbea36a1-d25d-4064-a1da-fbe0bcc20cd1",
   "metadata": {},
   "source": [
    "#### 3. Function to remove content from the document not necessary for the final text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d941d0-a76b-4ecb-834f-b26aa30dab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_soup(soup):\n",
    "    while soup.body is not None:\n",
    "        soup.body.unwrap()\n",
    "        \n",
    "    while soup.hi is not None:\n",
    "        soup.hi.unwrap()\n",
    "\n",
    "    while soup.pb is not None:\n",
    "        soup.pb.unwrap()\n",
    "\n",
    "    while soup.head is not None:\n",
    "        soup.head.unwrap()\n",
    "\n",
    "    while soup.div is not None:\n",
    "        soup.div.unwrap()\n",
    "\n",
    "    while soup.p is not None:\n",
    "        soup.p.unwrap()\n",
    "\n",
    "    while soup.foreign is not None:\n",
    "        soup.foreign.extract()\n",
    "\n",
    "    while soup.unclear is not None:\n",
    "        soup.unclear.extract()\n",
    "\n",
    "    while soup.signature is not None:\n",
    "        soup.signature.unwrap()\n",
    "\n",
    "    while soup.subhead is not None:\n",
    "        soup.subhead.unwrap()\n",
    "\n",
    "    while soup.metamark is not None:\n",
    "        soup.metamark.unwrap()\n",
    "\n",
    "    t = soup.find('name')\n",
    "    while t is not None:\n",
    "        t.unwrap()\n",
    "        t = soup.find('name')\n",
    "    \n",
    "    while soup.sic is not None:\n",
    "        soup.sic.unwrap()\n",
    "    \n",
    "    while soup.lb is not None:\n",
    "        soup.lb.unwrap()\n",
    "\n",
    "    while soup.subst is not None:\n",
    "        soup.subst.unwrap()\n",
    "        \n",
    "    return soup\n",
    "\n",
    "# Apply function to the soup object\n",
    "soup = clean_soup(soup.body)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e12ccb-9f17-490a-8629-0e41d7113a3a",
   "metadata": {},
   "source": [
    "#### 4. Generate Witness 1: only instant edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "360d91f3-5a11-4d69-90d2-65e5924615b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soupw1 = BeautifulSoup(str(soup), features=\"lxml-xml\")\n",
    "soupw2 = BeautifulSoup(str(soup), features=\"lxml-xml\")\n",
    "\n",
    "# Identify all top-level tags (not child edits within nested ones)\n",
    "top_level_tags = filter_child_edits(soupw2.find_all())\n",
    "\n",
    "# Generate Witness 1 (only instant edits applied)\n",
    "# Apply instant edits\n",
    "for tag in soupw1.find_all():\n",
    "    if tag.has_attr('instant'):\n",
    "        if tag['instant'].lower() == 'true':\n",
    "            soupw1 = apply_single_edit_op(soupw1, edit_op=tag)\n",
    "\n",
    "edits_to_ignore = []\n",
    "\n",
    "# Identify non-instant edits \n",
    "for tag in soupw1.find_all():\n",
    "    if not tag.has_attr('instant'):\n",
    "        if tag in top_level_tags:\n",
    "            edits_to_ignore.append(tag)\n",
    "    else:\n",
    "        if tag['instant'].lower() == 'false':\n",
    "            if tag in top_level_tags:\n",
    "                edits_to_ignore.append(tag)\n",
    "                \n",
    "# Apply \"ignore\" function to non-instant edits (i.e., revert their changes to before the edit was made)\n",
    "soupw1 = ignore_multiple_edit_ops(soupw1, edit_ops=edits_to_ignore)\n",
    "\n",
    "# Write result to file (Witness 1)\n",
    "with open(\"datasets/clean-data/aladin-witness1.txt\", \"w\") as outfile:\n",
    "    outfile.write(soupw1.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80b854-20e4-4776-88aa-07479d7af4cd",
   "metadata": {},
   "source": [
    "#### 5. Generate Witness 2: all edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fd12642-d589-4583-b2f5-cdecdd67f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Witness 2 (all edits applied)\n",
    "# Apply all edits to the document\n",
    "soupw2 = apply_multiple_edit_ops(soupw2, edit_ops=top_level_tags)\n",
    "\n",
    "# Write result to file (Witness 2)\n",
    "with open(\"datasets/clean-data/aladin-witness2.txt\", \"w\") as outfile:\n",
    "    outfile.write(soupw2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901407d9-ef07-4371-a5c7-4ce5b0b1c618",
   "metadata": {},
   "source": [
    "#### 6. Curiosity research: edit operation \"patterns\"\n",
    "\n",
    "List all the unique edit operation \"patterns\", \"nested structure\" or \"sequences\" and count the frequencies of each pattern in the document. The result is written to \"edit_patterns.json\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e96d1ac-d236-43cb-aac0-9b9c387e6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the edit pattern\n",
    "def render_edit_pattern(edit_op):\n",
    "    result = edit_op.name\n",
    "    current_nesting_depth = 1\n",
    "    if (result in [\"add\", \"del\", \"subst\"]):\n",
    "        depth = get_tag_nesting_depth(edit_op)\n",
    "        if depth == 1:\n",
    "            current_nesting_depth = 1\n",
    "            return result\n",
    "        else:\n",
    "            soup_obj = BeautifulSoup(str(edit_op), \"lxml-xml\")\n",
    "            soup_obj.find(edit_op.name, {\"id\": edit_op['id']}).unwrap()\n",
    "            tags = remove_non_root_tags(soup_obj.find_all())\n",
    "            if (len(tags) == 1):\n",
    "                result += \"L\" + render_edit_pattern(tags[0])\n",
    "            else:\n",
    "                result += \"L\"\n",
    "                for tag in tags:\n",
    "                    result += render_edit_pattern(tag) + \".\"\n",
    "        return result\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "# Store the edit patterns in a dict\n",
    "patterns = {}\n",
    "\n",
    "# Calculate the edit patterns and count their frequencies in the document\n",
    "for tag in top_level_tags:\n",
    "    res = render_edit_pattern(tag)\n",
    "    if (len(res) > 0):\n",
    "        if ((res not in patterns) and (not res.endswith('-1'))):\n",
    "            patterns[res] = 1\n",
    "        elif (res in patterns) and (not res.endswith('-1')):\n",
    "            patterns[res] = patterns[res] + 1\n",
    "\n",
    "        # if ((tag.name in [\"add\", \"del\", \"subst\"]) and (res != \"-1\") and res not in [\"add\", \"del\", \"substLdel.add.\"]):\n",
    "        #     print(tag)\n",
    "        #     print()\n",
    "        #     print(res)\n",
    "        #     print()\n",
    "        #     print()\n",
    "        \n",
    "# Write the results to file        \n",
    "with open(\"edit_patterns.json\", \"w\") as outfile:\n",
    "    json.dump(patterns, outfile)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
